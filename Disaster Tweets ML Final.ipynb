{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f38023a-de4b-4611-87c5-17c744ea84d8",
   "metadata": {},
   "source": [
    "Deep Learning for Disaster Tweet Classification - Machine learning Final \n",
    "Charisma Ricarte\n",
    "Trieu Do\n",
    "Jonathan Garcia\t\n",
    "\n",
    "Dataset source: https://www.kaggle.com/datasets/vstepanenko/disaster-tweets?select=tweets.csv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a4cc46-7979-4ab5-8bb8-2d3fa455e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Morgantown, WV</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3yrs after IPOB formed Biafra security Service...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>www</td>\n",
       "      <td>France agrees to send more troops to West Afri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>USA</td>\n",
       "      <td>While the press feasts off a tiny \"he-said, sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>North Pole</td>\n",
       "      <td>‚óè NEWS ‚óè #meduza #russia ‚òû Man who made Russia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>UK</td>\n",
       "      <td>Donald Trump posted a doctored islamophobia ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    keyword        location  \\\n",
       "0        0     ablaze             NaN   \n",
       "1        1     ablaze             NaN   \n",
       "2        2     ablaze   New York City   \n",
       "3        3     ablaze  Morgantown, WV   \n",
       "4        4     ablaze             NaN   \n",
       "...    ...        ...             ...   \n",
       "9995  9995  terrorism             NaN   \n",
       "9996  9996  terrorism             www   \n",
       "9997  9997  terrorism             USA   \n",
       "9998  9998  terrorism      North Pole   \n",
       "9999  9999  terrorism              UK   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
       "1     Telangana: Section 144 has been imposed in Bha...       1  \n",
       "2     Arsonist sets cars ablaze at dealership https:...       1  \n",
       "3     Arsonist sets cars ablaze at dealership https:...       1  \n",
       "4     \"Lord Jesus, your love brings freedom and pard...       0  \n",
       "...                                                 ...     ...  \n",
       "9995  3yrs after IPOB formed Biafra security Service...       0  \n",
       "9996  France agrees to send more troops to West Afri...       1  \n",
       "9997  While the press feasts off a tiny \"he-said, sh...       0  \n",
       "9998  ‚óè NEWS ‚óè #meduza #russia ‚òû Man who made Russia...       0  \n",
       "9999  Donald Trump posted a doctored islamophobia ph...       0  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"tweets.csv\", # the location to the data file\n",
    "                       sep=\",\", nrows = 10000\n",
    "                       )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9988bb-348a-449f-aae0-217e5dc6c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text of symbols and non-letters, etc. \n",
    "# should help standardize words, for example: \"FIRE!!!\", \"fire.\", and \"fireüî•\" now all map to \"fire\"\n",
    "# helps prevent un needed token usage \n",
    "\n",
    "import re        # for regular expressions (text cleaning)\n",
    "\n",
    "def clean_text(t):\n",
    "    t = t.lower()\n",
    "    t = re.sub(r\"http\\S+\", \"\", t)  # remove URLs\n",
    "    t = re.sub(r\"@\\w+\", \"\", t)     # remove mentions\n",
    "    t = re.sub(r\"#\", \"\", t)        # remove hashtag symbols (keep the word)\n",
    "    t = re.sub(r\"[^a-z\\s]\", \"\", t) # remove non-letters\n",
    "    return t.strip()\n",
    "dataset[\"clean_text\"] = dataset[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3719d228-04a6-40b1-8d11-12940a55f130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaaaacccccckkkkkkkk</th>\n",
       "      <th>aab</th>\n",
       "      <th>aadharcard</th>\n",
       "      <th>aalaathun</th>\n",
       "      <th>aampe</th>\n",
       "      <th>aampes</th>\n",
       "      <th>aap</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aayega</th>\n",
       "      <th>...</th>\n",
       "      <th>zonal</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomedin</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zulaykhas</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows √ó 19850 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaaaaaaaacccccckkkkkkkk  aab  aadharcard  aalaathun  aampe  aampes  \\\n",
       "0      0                        0    0           0          0      0       0   \n",
       "1      0                        0    0           0          0      0       0   \n",
       "2      0                        0    0           0          0      0       0   \n",
       "3      0                        0    0           0          0      0       0   \n",
       "4      0                        0    0           0          0      0       0   \n",
       "...   ..                      ...  ...         ...        ...    ...     ...   \n",
       "9995   0                        0    0           0          0      0       0   \n",
       "9996   0                        0    0           0          0      0       0   \n",
       "9997   0                        0    0           0          0      0       0   \n",
       "9998   0                        0    0           0          0      0       0   \n",
       "9999   0                        0    0           0          0      0       0   \n",
       "\n",
       "      aap  aaron  aayega  ...  zonal  zone  zoo  zoom  zoomedin  zorro  \\\n",
       "0       0      0       0  ...      0     0    0     0         0      0   \n",
       "1       0      0       0  ...      0     0    0     0         0      0   \n",
       "2       0      0       0  ...      0     0    0     0         0      0   \n",
       "3       0      0       0  ...      0     0    0     0         0      0   \n",
       "4       0      0       0  ...      0     0    0     0         0      0   \n",
       "...   ...    ...     ...  ...    ...   ...  ...   ...       ...    ...   \n",
       "9995    0      0       0  ...      0     0    0     0         0      0   \n",
       "9996    0      0       0  ...      0     0    0     0         0      0   \n",
       "9997    0      0       0  ...      0     0    0     0         0      0   \n",
       "9998    0      0       0  ...      0     0    0     0         0      0   \n",
       "9999    0      0       0  ...      0     0    0     0         0      0   \n",
       "\n",
       "      zuckerberg  zulaykhas  zuma  zw  \n",
       "0              0          0     0   0  \n",
       "1              0          0     0   0  \n",
       "2              0          0     0   0  \n",
       "3              0          0     0   0  \n",
       "4              0          0     0   0  \n",
       "...          ...        ...   ...  ..  \n",
       "9995           0          0     0   0  \n",
       "9996           0          0     0   0  \n",
       "9997           0          0     0   0  \n",
       "9998           0          0     0   0  \n",
       "9999           0          0     0   0  \n",
       "\n",
       "[10000 rows x 19850 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries to clean and prepare our dataset for our models - Bag of words binary feature matrix \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "vectorizer = CountVectorizer(binary=True, stop_words=\"english\") # 1 or 0 indicating if word appears in tweet and removes english words like \"the\", \"and\" and \"is\"\n",
    "X = vectorizer.fit_transform(dataset[\"clean_text\"]) # converts each tweet into a vector of 0s and 1s\n",
    "df_tf = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names_out()) # takes every word and places it as a column name \n",
    "df_tf # predictors (independent variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b16bd-a153-4b00-9543-bedf3d27e47f",
   "metadata": {},
   "source": [
    "Decided to try a different vectorizer - TF-IDF - weighted feature matrix \n",
    "This vectorizer will assign weights to words. Words with more importance get a higher weight while words with less importance get a smaller weight. \n",
    "It performs much better than the binary vectorizer above. There are more meaningful words found, and this will help in training models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d7e3c08-8e9c-4754-9a74-892a9a0c97f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aap</th>\n",
       "      <th>aap chronology</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abby</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc news</th>\n",
       "      <th>abiding</th>\n",
       "      <th>...</th>\n",
       "      <th>zip bts</th>\n",
       "      <th>zip photos</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombie apocalypse</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zuma did</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aap  aap chronology   ab  abandon  abandoned  abbott  abby  abc  abc news  \\\n",
       "0   0.0             0.0  0.0      0.0        0.0     0.0   0.0  0.0       0.0   \n",
       "1   0.0             0.0  0.0      0.0        0.0     0.0   0.0  0.0       0.0   \n",
       "2   0.0             0.0  0.0      0.0        0.0     0.0   0.0  0.0       0.0   \n",
       "3   0.0             0.0  0.0      0.0        0.0     0.0   0.0  0.0       0.0   \n",
       "4   0.0             0.0  0.0      0.0        0.0     0.0   0.0  0.0       0.0   \n",
       "..  ...             ...  ...      ...        ...     ...   ...  ...       ...   \n",
       "95  0.0             0.0  0.0      0.0        0.0     0.0   0.0  0.0       0.0   \n",
       "96  0.0             0.0  0.0      0.0        0.0     0.0   0.0  0.0       0.0   \n",
       "97  0.0             0.0  0.0      0.0        0.0     0.0   0.0  0.0       0.0   \n",
       "98  0.0             0.0  0.0      0.0        0.0     0.0   0.0  0.0       0.0   \n",
       "99  0.0             0.0  0.0      0.0        0.0     0.0   0.0  0.0       0.0   \n",
       "\n",
       "    abiding  ...  zip bts  zip photos  zombie  zombie apocalypse  zombies  \\\n",
       "0       0.0  ...      0.0         0.0     0.0                0.0      0.0   \n",
       "1       0.0  ...      0.0         0.0     0.0                0.0      0.0   \n",
       "2       0.0  ...      0.0         0.0     0.0                0.0      0.0   \n",
       "3       0.0  ...      0.0         0.0     0.0                0.0      0.0   \n",
       "4       0.0  ...      0.0         0.0     0.0                0.0      0.0   \n",
       "..      ...  ...      ...         ...     ...                ...      ...   \n",
       "95      0.0  ...      0.0         0.0     0.0                0.0      0.0   \n",
       "96      0.0  ...      0.0         0.0     0.0                0.0      0.0   \n",
       "97      0.0  ...      0.0         0.0     0.0                0.0      0.0   \n",
       "98      0.0  ...      0.0         0.0     0.0                0.0      0.0   \n",
       "99      0.0  ...      0.0         0.0     0.0                0.0      0.0   \n",
       "\n",
       "    zone  zoo  zoom  zuma  zuma did  \n",
       "0    0.0  0.0   0.0   0.0       0.0  \n",
       "1    0.0  0.0   0.0   0.0       0.0  \n",
       "2    0.0  0.0   0.0   0.0       0.0  \n",
       "3    0.0  0.0   0.0   0.0       0.0  \n",
       "4    0.0  0.0   0.0   0.0       0.0  \n",
       "..   ...  ...   ...   ...       ...  \n",
       "95   0.0  0.0   0.0   0.0       0.0  \n",
       "96   0.0  0.0   0.0   0.0       0.0  \n",
       "97   0.0  0.0   0.0   0.0       0.0  \n",
       "98   0.0  0.0   0.0   0.0       0.0  \n",
       "99   0.0  0.0   0.0   0.0       0.0  \n",
       "\n",
       "[100 rows x 20000 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    norm=\"l2\",\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1,2),      # include unigrams + bigrams\n",
    "    max_features=20000,     # cap vocab size - helps remove characters or words that have no meaning or very rare occurence\n",
    "    lowercase=True\n",
    ")\n",
    "X = vectorizer.fit_transform(dataset[\"clean_text\"])  # use your cleaned text column\n",
    "\n",
    "# take a look at the first 100 rows of new dataframe \n",
    "pd.DataFrame(X[:100].toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15d9069a-ec31-48c9-aa04-32bde5c0014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.940     0.909     0.924      1647\n",
      "           1      0.631     0.728     0.676       353\n",
      "\n",
      "    accuracy                          0.877      2000\n",
      "   macro avg      0.786     0.818     0.800      2000\n",
      "weighted avg      0.885     0.877     0.880      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Partition the data set\n",
    "# create pipeline to prevent data leakage \n",
    "# Setup baseline - logistic regression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_text = dataset[\"clean_text\"]  \n",
    "y = dataset[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.20, random_state=123, stratify=y\n",
    ")\n",
    "\n",
    "# Logistic Regression model- baseline\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_features=20000),\n",
    "    LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3245e-8035-4364-97f4-a7ec40cee3f5",
   "metadata": {},
   "source": [
    "0 = Non-disaster tweets \n",
    "1 = Disaster Tweets \n",
    "Precision = out of all tweets predicted as ‚Äúdisaster,‚Äù how many actually were?\n",
    "Recall = out of all real disaster tweets, how many did the model correctly identify?\n",
    "F1-score = harmonic mean of precision & recall (balances both)\n",
    "Support = number of true samples in that class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7493e-4d28-42c6-9c6b-dbac9a778aff",
   "metadata": {},
   "source": [
    "1st run \n",
    "The LR model is performing well overall for a 70/20 split \n",
    "It does really well at finding non-disaster tweets with an F1-score of 92% and ok at finding disaster tweets at 67% \n",
    "The support reveals that there were over 2400 samples of \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0      0.936     0.913     0.924      2470\n",
    "           1      0.635     0.708     0.669       530\n",
    "\n",
    "    accuracy                          0.876      3000\n",
    "   macro avg      0.785     0.810     0.797      3000\n",
    "weighted avg      0.882     0.876     0.879      3000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45098a1-de3d-4d13-8aaf-81ac2a82629e",
   "metadata": {},
   "source": [
    "2nd run - will use this one for baseline\n",
    "LR model baseline improved with an 80/20 split. \n",
    "The F1 score improved for disaster tweet detection by almost 1 point. Accuracy, macro avg, and weighted average also improved slightly. \n",
    "\n",
    " precision    recall  f1-score   support\n",
    "\n",
    "           0      0.940     0.909     0.924      1647\n",
    "           1      0.631     0.728     0.676       353\n",
    "\n",
    "    accuracy                          0.877      2000\n",
    "   macro avg      0.786     0.818     0.800      2000\n",
    "weighted avg      0.885     0.877     0.880      2000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
