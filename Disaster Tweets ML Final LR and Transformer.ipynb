{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f38023a-de4b-4611-87c5-17c744ea84d8",
   "metadata": {},
   "source": [
    "Deep Learning for Disaster Tweet Classification - Machine learning Final \n",
    "Charisma Ricarte\n",
    "Trieu Do\n",
    "Jonathan Garcia\t\n",
    "\n",
    "Dataset source: https://www.kaggle.com/datasets/vstepanenko/disaster-tweets?select=tweets.csv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd7d7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a4cc46-7979-4ab5-8bb8-2d3fa455e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Morgantown, WV</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3yrs after IPOB formed Biafra security Service...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>www</td>\n",
       "      <td>France agrees to send more troops to West Afri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>USA</td>\n",
       "      <td>While the press feasts off a tiny \"he-said, sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>North Pole</td>\n",
       "      <td>‚óè NEWS ‚óè #meduza #russia ‚òû Man who made Russia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>UK</td>\n",
       "      <td>Donald Trump posted a doctored islamophobia ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    keyword        location  \\\n",
       "0        0     ablaze             NaN   \n",
       "1        1     ablaze             NaN   \n",
       "2        2     ablaze   New York City   \n",
       "3        3     ablaze  Morgantown, WV   \n",
       "4        4     ablaze             NaN   \n",
       "...    ...        ...             ...   \n",
       "9995  9995  terrorism             NaN   \n",
       "9996  9996  terrorism             www   \n",
       "9997  9997  terrorism             USA   \n",
       "9998  9998  terrorism      North Pole   \n",
       "9999  9999  terrorism              UK   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
       "1     Telangana: Section 144 has been imposed in Bha...       1  \n",
       "2     Arsonist sets cars ablaze at dealership https:...       1  \n",
       "3     Arsonist sets cars ablaze at dealership https:...       1  \n",
       "4     \"Lord Jesus, your love brings freedom and pard...       0  \n",
       "...                                                 ...     ...  \n",
       "9995  3yrs after IPOB formed Biafra security Service...       0  \n",
       "9996  France agrees to send more troops to West Afri...       1  \n",
       "9997  While the press feasts off a tiny \"he-said, sh...       0  \n",
       "9998  ‚óè NEWS ‚óè #meduza #russia ‚òû Man who made Russia...       0  \n",
       "9999  Donald Trump posted a doctored islamophobia ph...       0  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"tweets.csv\", # the location to the data file\n",
    "                       sep=\",\", nrows = 10000\n",
    "                       )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c9988bb-348a-449f-aae0-217e5dc6c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text of symbols and non-letters, etc. \n",
    "# should help standardize words, for example: \"FIRE!!!\", \"fire.\", and \"fireüî•\" now all map to \"fire\"\n",
    "# helps prevent un needed token usage \n",
    "\n",
    "import re        # for regular expressions (text cleaning)\n",
    "\n",
    "def clean_text(t):\n",
    "    t = t.lower()\n",
    "    t = re.sub(r\"http\\S+\", \"\", t)  # remove URLs\n",
    "    t = re.sub(r\"@\\w+\", \"\", t)     # remove mentions\n",
    "    t = re.sub(r\"#\", \"\", t)        # remove hashtag symbols (keep the word)\n",
    "    t = re.sub(r\"[^a-z\\s]\", \"\", t) # remove non-letters\n",
    "    return t.strip()\n",
    "dataset[\"clean_text\"] = dataset[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3719d228-04a6-40b1-8d11-12940a55f130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaaaacccccckkkkkkkk</th>\n",
       "      <th>aab</th>\n",
       "      <th>aadharcard</th>\n",
       "      <th>aalaathun</th>\n",
       "      <th>aampe</th>\n",
       "      <th>aampes</th>\n",
       "      <th>aap</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aayega</th>\n",
       "      <th>...</th>\n",
       "      <th>zonal</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomedin</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zulaykhas</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows √ó 19850 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaaaaaaaacccccckkkkkkkk  aab  aadharcard  aalaathun  aampe  aampes  \\\n",
       "0      0                        0    0           0          0      0       0   \n",
       "1      0                        0    0           0          0      0       0   \n",
       "2      0                        0    0           0          0      0       0   \n",
       "3      0                        0    0           0          0      0       0   \n",
       "4      0                        0    0           0          0      0       0   \n",
       "...   ..                      ...  ...         ...        ...    ...     ...   \n",
       "9995   0                        0    0           0          0      0       0   \n",
       "9996   0                        0    0           0          0      0       0   \n",
       "9997   0                        0    0           0          0      0       0   \n",
       "9998   0                        0    0           0          0      0       0   \n",
       "9999   0                        0    0           0          0      0       0   \n",
       "\n",
       "      aap  aaron  aayega  ...  zonal  zone  zoo  zoom  zoomedin  zorro  \\\n",
       "0       0      0       0  ...      0     0    0     0         0      0   \n",
       "1       0      0       0  ...      0     0    0     0         0      0   \n",
       "2       0      0       0  ...      0     0    0     0         0      0   \n",
       "3       0      0       0  ...      0     0    0     0         0      0   \n",
       "4       0      0       0  ...      0     0    0     0         0      0   \n",
       "...   ...    ...     ...  ...    ...   ...  ...   ...       ...    ...   \n",
       "9995    0      0       0  ...      0     0    0     0         0      0   \n",
       "9996    0      0       0  ...      0     0    0     0         0      0   \n",
       "9997    0      0       0  ...      0     0    0     0         0      0   \n",
       "9998    0      0       0  ...      0     0    0     0         0      0   \n",
       "9999    0      0       0  ...      0     0    0     0         0      0   \n",
       "\n",
       "      zuckerberg  zulaykhas  zuma  zw  \n",
       "0              0          0     0   0  \n",
       "1              0          0     0   0  \n",
       "2              0          0     0   0  \n",
       "3              0          0     0   0  \n",
       "4              0          0     0   0  \n",
       "...          ...        ...   ...  ..  \n",
       "9995           0          0     0   0  \n",
       "9996           0          0     0   0  \n",
       "9997           0          0     0   0  \n",
       "9998           0          0     0   0  \n",
       "9999           0          0     0   0  \n",
       "\n",
       "[10000 rows x 19850 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries to clean and prepare our dataset for our models - Bag of words binary feature matrix \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "vectorizer = CountVectorizer(binary=True, stop_words=\"english\") # 1 or 0 indicating if word appears in tweet and removes english words like \"the\", \"and\" and \"is\"\n",
    "X = vectorizer.fit_transform(dataset[\"clean_text\"]) # converts each tweet into a vector of 0s and 1s\n",
    "df_tf = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names_out()) # takes every word and places it as a column name \n",
    "df_tf # predictors (independent variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b16bd-a153-4b00-9543-bedf3d27e47f",
   "metadata": {},
   "source": [
    "Decided to try a different vectorizer - TF-IDF - weighted feature matrix \n",
    "This vectorizer will assign weights to words. Words with more importance get a higher weight while words with less importance get a smaller weight. \n",
    "It performs much better than the binary vectorizer above. There are more meaningful words found, and this will help in training models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7e3c08-8e9c-4754-9a74-892a9a0c97f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aab battle</th>\n",
       "      <th>aadharcard</th>\n",
       "      <th>aadharcard ad</th>\n",
       "      <th>aalaathun</th>\n",
       "      <th>aalaathun balaa</th>\n",
       "      <th>aampe</th>\n",
       "      <th>aampe life</th>\n",
       "      <th>aampes</th>\n",
       "      <th>aampes queen</th>\n",
       "      <th>aap</th>\n",
       "      <th>...</th>\n",
       "      <th>zombies run</th>\n",
       "      <th>zombies time</th>\n",
       "      <th>zombievirus</th>\n",
       "      <th>zonal</th>\n",
       "      <th>zonal cooling</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zuma did</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aab battle  aadharcard  aadharcard ad  aalaathun  aalaathun balaa  aampe  \\\n",
       "0          0.0         0.0            0.0        0.0              0.0    0.0   \n",
       "1          0.0         0.0            0.0        0.0              0.0    0.0   \n",
       "2          0.0         0.0            0.0        0.0              0.0    0.0   \n",
       "3          0.0         0.0            0.0        0.0              0.0    0.0   \n",
       "4          0.0         0.0            0.0        0.0              0.0    0.0   \n",
       "..         ...         ...            ...        ...              ...    ...   \n",
       "95         0.0         0.0            0.0        0.0              0.0    0.0   \n",
       "96         0.0         0.0            0.0        0.0              0.0    0.0   \n",
       "97         0.0         0.0            0.0        0.0              0.0    0.0   \n",
       "98         0.0         0.0            0.0        0.0              0.0    0.0   \n",
       "99         0.0         0.0            0.0        0.0              0.0    0.0   \n",
       "\n",
       "    aampe life  aampes  aampes queen  aap  ...  zombies run  zombies time  \\\n",
       "0          0.0     0.0           0.0  0.0  ...          0.0           0.0   \n",
       "1          0.0     0.0           0.0  0.0  ...          0.0           0.0   \n",
       "2          0.0     0.0           0.0  0.0  ...          0.0           0.0   \n",
       "3          0.0     0.0           0.0  0.0  ...          0.0           0.0   \n",
       "4          0.0     0.0           0.0  0.0  ...          0.0           0.0   \n",
       "..         ...     ...           ...  ...  ...          ...           ...   \n",
       "95         0.0     0.0           0.0  0.0  ...          0.0           0.0   \n",
       "96         0.0     0.0           0.0  0.0  ...          0.0           0.0   \n",
       "97         0.0     0.0           0.0  0.0  ...          0.0           0.0   \n",
       "98         0.0     0.0           0.0  0.0  ...          0.0           0.0   \n",
       "99         0.0     0.0           0.0  0.0  ...          0.0           0.0   \n",
       "\n",
       "    zombievirus  zonal  zonal cooling  zone  zoo  zoom  zuma  zuma did  \n",
       "0           0.0    0.0            0.0   0.0  0.0   0.0   0.0       0.0  \n",
       "1           0.0    0.0            0.0   0.0  0.0   0.0   0.0       0.0  \n",
       "2           0.0    0.0            0.0   0.0  0.0   0.0   0.0       0.0  \n",
       "3           0.0    0.0            0.0   0.0  0.0   0.0   0.0       0.0  \n",
       "4           0.0    0.0            0.0   0.0  0.0   0.0   0.0       0.0  \n",
       "..          ...    ...            ...   ...  ...   ...   ...       ...  \n",
       "95          0.0    0.0            0.0   0.0  0.0   0.0   0.0       0.0  \n",
       "96          0.0    0.0            0.0   0.0  0.0   0.0   0.0       0.0  \n",
       "97          0.0    0.0            0.0   0.0  0.0   0.0   0.0       0.0  \n",
       "98          0.0    0.0            0.0   0.0  0.0   0.0   0.0       0.0  \n",
       "99          0.0    0.0            0.0   0.0  0.0   0.0   0.0       0.0  \n",
       "\n",
       "[100 rows x 20000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    norm=\"l2\",\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1,2),      # include unigrams + bigrams\n",
    "    max_features=20000,     # cap vocab size - helps remove characters or words that have no meaning or very rare occurence\n",
    "    lowercase=True\n",
    ")\n",
    "X = vectorizer.fit_transform(dataset[\"clean_text\"])  # use your cleaned text column\n",
    "\n",
    "# take a look at the first 100 rows of new dataframe \n",
    "pd.DataFrame(X[:100].toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d9069a-ec31-48c9-aa04-32bde5c0014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.942     0.910     0.926      1647\n",
      "           1      0.638     0.739     0.685       353\n",
      "\n",
      "    accuracy                          0.880      2000\n",
      "   macro avg      0.790     0.825     0.805      2000\n",
      "weighted avg      0.889     0.880     0.883      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Partition the data set\n",
    "# create pipeline to prevent data leakage \n",
    "# Setup baseline - logistic regression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_text = dataset[\"clean_text\"]  \n",
    "y = dataset[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.20, random_state=123, stratify=y\n",
    ")\n",
    "\n",
    "# Logistic Regression model- baseline\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_features=20000),\n",
    "    LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3245e-8035-4364-97f4-a7ec40cee3f5",
   "metadata": {},
   "source": [
    "0 = Non-disaster tweets \n",
    "1 = Disaster Tweets \n",
    "Precision = out of all tweets predicted as ‚Äúdisaster,‚Äù how many actually were?\n",
    "Recall = out of all real disaster tweets, how many did the model correctly identify?\n",
    "F1-score = harmonic mean of precision & recall (balances both)\n",
    "Support = number of true samples in that class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7493e-4d28-42c6-9c6b-dbac9a778aff",
   "metadata": {},
   "source": [
    "1st run \n",
    "The LR model is performing well overall for a 70/20 split \n",
    "It does really well at finding non-disaster tweets with an F1-score of 92% and ok at finding disaster tweets at 67% \n",
    "The support reveals that there were over 2400 samples of \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0      0.936     0.913     0.924      2470\n",
    "           1      0.635     0.708     0.669       530\n",
    "\n",
    "    accuracy                          0.876      3000\n",
    "   macro avg      0.785     0.810     0.797      3000\n",
    "weighted avg      0.882     0.876     0.879      3000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45098a1-de3d-4d13-8aaf-81ac2a82629e",
   "metadata": {},
   "source": [
    "2nd run - will use this one for baseline\n",
    "LR model baseline improved with an 80/20 split. \n",
    "The F1 score improved for disaster tweet detection by almost 1 point. Accuracy, macro avg, and weighted average also improved slightly. \n",
    "\n",
    " precision    recall  f1-score   support\n",
    "\n",
    "           0      0.940     0.909     0.924      1647\n",
    "           1      0.631     0.728     0.676       353\n",
    "\n",
    "    accuracy                          0.877      2000\n",
    "   macro avg      0.786     0.818     0.800      2000\n",
    "weighted avg      0.885     0.877     0.880      2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fa79c8",
   "metadata": {},
   "source": [
    "Setup environment for Transformer Model \n",
    "\n",
    "install transformer library\n",
    "\n",
    "open terminal \n",
    "\n",
    "\n",
    "conda activate # shouldnt need this - > <your-env-name>\n",
    "    \n",
    "conda install -c huggingface transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c95b05ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root contents: ['tweets.csv', 'src', 'Disaster Tweets ML Final.ipynb', 'Untitled.ipynb', 'main.py', 'requirements.txt', 'README.md', '.ipynb_checkpoints', 'training_loss_curve.png', 'data', '__pycache__', 'eda_target_distribution.png', 'metrics_summary.png']\n",
      "src contents: ['utils.py', 'train_eval.py', 'model.py', '__pycache__', 'preprocess.py']\n",
      "\r\n",
      "Binary file src/__pycache__/preprocess.cpython-310.pyc matches\r\n",
      "Binary file src/__pycache__/preprocess.cpython-312.pyc matches\r\n",
      "Binary file src/__pycache__/model.cpython-310.pyc matches\r\n",
      "Binary file src/__pycache__/model.cpython-312.pyc matches\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import os, textwrap, sys\n",
    "\n",
    "print(\"Repo root contents:\", os.listdir(\".\"))\n",
    "if \"src\" in os.listdir(\".\"):\n",
    "    print(\"src contents:\", os.listdir(\"src\"))\n",
    "else:\n",
    "    print(\"No src folder found\")\n",
    "\n",
    "# Quick search for anything with 'transformer' in the code\n",
    "!grep -R \"transformer\" -n src || echo \"No 'transformer' string found in src\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e943b90",
   "metadata": {},
   "source": [
    "# install transformer library\n",
    "open terminal \n",
    "cd ml_final\n",
    "conda create --prefix ./env python=3.10 -y\n",
    "conda activate ./env \n",
    "conda install -c conda-forge transformers -y\n",
    "conda install scikit-learn -y\n",
    "conda install matplotlib -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fbcc3d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable for this notebook: /scratch/user/u.jg335414/.conda/envs/pytorch_env/bin/python\n",
      "Requirement already satisfied: transformers in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from requests->transformers) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable for this notebook:\", sys.executable)\n",
    "\n",
    "# Install transformers into THIS exact Python env\n",
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bf9ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (4.4.1)\n",
      "Requirement already satisfied: accelerate in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: psutil in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from accelerate) (2.5.1+cu121)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: networkx in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.9.86)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /ccstar/scratch/user/u.jg335414/.conda/envs/pytorch_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff526510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "Warning: 2 possible package resolutions (only showing differing packages):\n",
      "  - defaults/linux-64::markdown-3.8-py311h06a4308_0, defaults/linux-64::markdown-it-py-2.2.0-py311h06a4308_1\n",
      "  - defaults/linux-64::markdown-3.4.1-py311h06a4308_0, defaults/linux-64::markdown-it-py-4.0.0-py311h06a4308done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 25.9.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.9.1\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /sw/eb/sw/Anaconda3/2023.09-0\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  aiodns             pkgs/main/linux-64::aiodns-3.5.0-py311h06a4308_1 \n",
      "  aiohappyeyeballs   pkgs/main/linux-64::aiohappyeyeballs-2.6.1-py311h06a4308_0 \n",
      "  astropy-iers-data  pkgs/main/linux-64::astropy-iers-data-0.2025.11.10.0.38.31-py311h06a4308_0 \n",
      "  async-lru          pkgs/main/linux-64::async-lru-2.0.5-py311h06a4308_0 \n",
      "  backports.tarfile  pkgs/main/linux-64::backports.tarfile-1.2.0-py311h06a4308_0 \n",
      "  blinker            pkgs/main/linux-64::blinker-1.9.0-py311h06a4308_0 \n",
      "  brotlicffi         pkgs/main/linux-64::brotlicffi-1.1.0.0-py311hbdd6827_0 \n",
      "  cairo              pkgs/main/linux-64::cairo-1.18.4-h44eff21_0 \n",
      "  fribidi            pkgs/main/linux-64::fribidi-1.0.10-h7b6447c_0 \n",
      "  glib-tools         pkgs/main/linux-64::glib-tools-2.84.4-h8875d55_0 \n",
      "  graphite2          pkgs/main/linux-64::graphite2-1.3.14-h295c915_1 \n",
      "  h11                pkgs/main/linux-64::h11-0.16.0-py311h06a4308_1 \n",
      "  harfbuzz           pkgs/main/linux-64::harfbuzz-10.2.0-hdfddeaa_1 \n",
      "  hf-xet             pkgs/main/linux-64::hf-xet-1.1.8-py311h84c0859_0 \n",
      "  httpcore           pkgs/main/linux-64::httpcore-1.0.9-py311h06a4308_0 \n",
      "  httpx              pkgs/main/linux-64::httpx-0.28.1-py311h06a4308_1 \n",
      "  jansson            pkgs/main/linux-64::jansson-2.14-h5eee18b_1 \n",
      "  jaraco.context     pkgs/main/linux-64::jaraco.context-6.0.0-py311h06a4308_0 \n",
      "  jaraco.functools   pkgs/main/linux-64::jaraco.functools-4.1.0-py311h06a4308_0 \n",
      "  jsonschema-specif~ pkgs/main/linux-64::jsonschema-specifications-2025.9.1-py311h06a4308_0 \n",
      "  jupyter-lsp        pkgs/main/linux-64::jupyter-lsp-2.2.5-py311h06a4308_0 \n",
      "  jupyter_server_te~ pkgs/main/linux-64::jupyter_server_terminals-0.5.3-py311h06a4308_0 \n",
      "  libgcc             pkgs/main/linux-64::libgcc-15.2.0-h69a1729_7 \n",
      "  libgfortran        pkgs/main/linux-64::libgfortran-15.2.0-h166f726_7 \n",
      "  libglib            pkgs/main/linux-64::libglib-2.84.4-h77a78f3_0 \n",
      "  libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 \n",
      "  libkrb5            pkgs/main/linux-64::libkrb5-1.21.3-h520c7b4_4 \n",
      "  libopenjpeg        pkgs/main/linux-64::libopenjpeg-2.5.4-hee96239_1 \n",
      "  libstdcxx          pkgs/main/linux-64::libstdcxx-15.2.0-h39759b7_7 \n",
      "  libuv              pkgs/main/linux-64::libuv-1.48.0-h5eee18b_0 \n",
      "  lmdb               pkgs/main/linux-64::lmdb-0.9.31-hb25bd0a_0 \n",
      "  mbedtls            pkgs/main/linux-64::mbedtls-3.5.1-h6a678d5_1 \n",
      "  mpi4py             pkgs/main/linux-64::mpi4py-4.0.3-py311hb6b6513_0 \n",
      "  narwhals           pkgs/main/linux-64::narwhals-2.7.0-py311h06a4308_0 \n",
      "  nbconvert-core     pkgs/main/linux-64::nbconvert-core-7.16.6-py311h06a4308_0 \n",
      "  nbconvert-pandoc   pkgs/main/linux-64::nbconvert-pandoc-7.16.6-py311h06a4308_0 \n",
      "  overrides          pkgs/main/linux-64::overrides-7.7.0-py311h06a4308_0 \n",
      "  pandoc             pkgs/main/linux-64::pandoc-3.8-h06a4308_0 \n",
      "  pixman             pkgs/main/linux-64::pixman-0.46.4-h7934f7d_0 \n",
      "  propcache          pkgs/main/linux-64::propcache-0.3.1-py311h5eee18b_0 \n",
      "  pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n",
      "  pycares            pkgs/main/linux-64::pycares-4.10.0-py311ha137689_0 \n",
      "  pytokens           pkgs/main/linux-64::pytokens-0.2.0-py311h06a4308_0 \n",
      "  referencing        pkgs/main/linux-64::referencing-0.37.0-py311h06a4308_0 \n",
      "  rich               pkgs/main/linux-64::rich-14.2.0-py311h06a4308_0 \n",
      "  roman-numerals-py  pkgs/main/linux-64::roman-numerals-py-3.1.0-py311h06a4308_0 \n",
      "  rpds-py            pkgs/main/linux-64::rpds-py-0.28.0-py311h498d7c9_0 \n",
      "  tomli              pkgs/main/linux-64::tomli-2.2.1-py311h06a4308_0 \n",
      "  uvloop             pkgs/main/linux-64::uvloop-0.22.1-py312h939ff40_1 \n",
      "  xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 \n",
      "  xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n",
      "  xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n",
      "  xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n",
      "  xorg-libxext       pkgs/main/linux-64::xorg-libxext-1.3.6-h9b100fa_0 \n",
      "  xorg-libxrender    pkgs/main/linux-64::xorg-libxrender-0.9.12-h9b100fa_0 \n",
      "  xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  aiofiles-22.1.0-py311h06a4308_0\n",
      "  aiosqlite-0.18.0-py311h06a4308_0\n",
      "  async-timeout-4.0.2-py311h06a4308_0\n",
      "  backcall-0.2.0-pyhd3eb1b0_0\n",
      "  brotli-1.0.9-h5eee18b_7\n",
      "  brotli-bin-1.0.9-h5eee18b_7\n",
      "  brotlipy-0.7.0-py311h5eee18b_1002\n",
      "  brunsli-0.1-h2531618_0\n",
      "  cfitsio-3.470-h5893167_7\n",
      "  charls-2.2.0-h2531618_0\n",
      "  datashape-0.5.4-py311h06a4308_1\n",
      "  entrypoints-0.4-py311h06a4308_0\n",
      "  giflib-5.2.1-h5eee18b_3\n",
      "  imagecodecs-2023.1.23-py311h8105a5c_0\n",
      "  importlib_metadata-6.0.0-hd3eb1b0_0\n",
      "  jinja2-time-0.2.0-pyhd3eb1b0_3\n",
      "  jupyter_server_fileid-0.9.0-py311h06a4308_0\n",
      "  jupyter_server_ydoc-0.8.0-py311h06a4308_1\n",
      "  jupyter_ydoc-0.2.4-py311h06a4308_0\n",
      "  jxrlib-1.1-h7b6447c_2\n",
      "  libaec-1.0.4-he6710b0_1\n",
      "  libwebp-1.3.2-h11a3e52_0\n",
      "  libzopfli-1.0.3-he6710b0_0\n",
      "  munkres-1.1.4-py_0\n",
      "  nbclassic-0.5.5-py311h06a4308_0\n",
      "  openjpeg-2.4.0-h3ad879b_0\n",
      "  pathlib-1.0.1-pyhd3eb1b0_1\n",
      "  pcre-8.45-h295c915_0\n",
      "  poyo-0.5.0-pyhd3eb1b0_0\n",
      "  pyrsistent-0.18.0-py311h5eee18b_0\n",
      "  python-snappy-0.6.1-py311h6a678d5_0\n",
      "  qtwebkit-5.212-h3fafdc1_5\n",
      "  tenacity-8.2.2-py311h06a4308_0\n",
      "  unidecode-1.2.0-pyhd3eb1b0_0\n",
      "  y-py-0.5.9-py311h52d8a92_0\n",
      "  ypy-websocket-0.8.2-py311h06a4308_0\n",
      "  zfp-1.0.0-h6a678d5_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  aiobotocore                         2.5.0-py311h06a4308_0 --> 2.25.0-py311h06a4308_0 \n",
      "  aiohttp                             3.8.5-py311h5eee18b_0 --> 3.13.2-py311hee96239_0 \n",
      "  aioitertools       pkgs/main/noarch::aioitertools-0.7.1-~ --> pkgs/main/linux-64::aioitertools-0.12.0-py311h06a4308_0 \n",
      "  aiosignal          pkgs/main/noarch::aiosignal-1.2.0-pyh~ --> pkgs/main/linux-64::aiosignal-1.4.0-py311h06a4308_0 \n",
      "  alabaster          pkgs/main/noarch::alabaster-0.7.12-py~ --> pkgs/main/linux-64::alabaster-0.7.16-py311h06a4308_0 \n",
      "  anyio                               3.5.0-py311h06a4308_0 --> 4.10.0-py311h06a4308_0 \n",
      "  aom                                      3.6.0-h6a678d5_0 --> 3.12.1-h7934f7d_0 \n",
      "  argon2-cffi-bindi~                 21.2.0-py311h5eee18b_0 --> 25.1.0-py311hee96239_0 \n",
      "  arrow                               1.2.3-py311h06a4308_1 --> 1.4.0-py311h06a4308_0 \n",
      "  astropy                               5.1-py311hbed6279_0 --> 7.1.1-py311haa0f9ac_0 \n",
      "  asttokens          pkgs/main/noarch::asttokens-2.0.5-pyh~ --> pkgs/main/linux-64::asttokens-3.0.0-py311h06a4308_0 \n",
      "  attrs                              22.1.0-py311h06a4308_0 --> 25.4.0-py311h06a4308_2 \n",
      "  automat             pkgs/main/noarch::automat-20.2.0-py_0 --> pkgs/main/linux-64::automat-24.8.1-py311h06a4308_0 \n",
      "  autopep8                               1.6.0-pyhd3eb1b0_1 --> 2.0.4-pyhd3eb1b0_0 \n",
      "  babel                              2.11.0-py311h06a4308_0 --> 2.16.0-py311h06a4308_0 \n",
      "  backports                                1.1-pyhd3eb1b0_0 --> 1.1-pyhd3eb1b0_1 \n",
      "  bcrypt                              3.2.0-py311h5eee18b_1 --> 5.0.0-py311h498d7c9_0 \n",
      "  beautifulsoup4                     4.12.2-py311h06a4308_0 --> 4.13.5-py311h06a4308_0 \n",
      "  black                              23.3.0-py311h06a4308_0 --> 25.9.0-py311h06a4308_0 \n",
      "  bleach             pkgs/main/noarch::bleach-4.1.0-pyhd3e~ --> pkgs/main/linux-64::bleach-6.2.0-py311h06a4308_0 \n",
      "  blosc                                   1.21.3-h6a678d5_0 --> 1.21.6-hf7d4471_0 \n",
      "  bokeh                               3.2.1-py311h92b7b1e_0 --> 3.8.0-py311h06a4308_0 \n",
      "  boltons                            23.0.0-py311h06a4308_0 --> 25.0.0-py311h06a4308_0 \n",
      "  boost-cpp                              1.73.0-h7f8727e_12 --> 1.82.0-hdb19cb5_2 \n",
      "  botocore                          1.29.76-py311h06a4308_0 --> 1.40.46-py311h06a4308_0 \n",
      "  bottleneck                          1.3.5-py311hbed6279_0 --> 1.4.2-py311haa0f9ac_1 \n",
      "  bzip2                                    1.0.8-h7b6447c_0 --> 1.0.8-h5eee18b_6 \n",
      "  c-ares                                  1.19.1-h5eee18b_0 --> 1.34.5-hef5626c_0 \n",
      "  c-blosc2                                 2.8.0-h6a678d5_0 --> 2.12.0-h80c7b02_0 \n",
      "  ca-certificates                     2023.08.22-h06a4308_0 --> 2025.11.4-h06a4308_0 \n",
      "  certifi                         2023.7.22-py311h06a4308_0 --> 2025.11.12-py311h06a4308_0 \n",
      "  cffi                               1.15.1-py311h5eee18b_3 --> 2.0.0-py311h4eded50_1 \n",
      "  chardet                          4.0.0-py311h06a4308_1003 --> 5.2.0-py311h06a4308_0 \n",
      "  charset-normalizer pkgs/main/noarch::charset-normalizer-~ --> pkgs/main/linux-64::charset-normalizer-3.4.4-py311h06a4308_0 \n",
      "  click                               8.0.4-py311h06a4308_0 --> 8.2.1-py311h06a4308_0 \n",
      "  cloudpickle                         2.2.1-py311h06a4308_0 --> 3.1.1-py311h06a4308_0 \n",
      "  colorcet                            3.0.1-py311h06a4308_0 --> 3.1.0-py311h06a4308_0 \n",
      "  comm                                0.1.2-py311h06a4308_0 --> 0.2.3-py311h06a4308_0 \n",
      "  conda-index                         0.3.0-py311h06a4308_0 --> 0.7.0-py311h06a4308_0 \n",
      "  conda-repo-cli                     1.0.75-py311h06a4308_0 --> 1.0.173-py311h06a4308_0 \n",
      "  constantly                         15.1.0-py311h06a4308_0 --> 23.10.4-py311h06a4308_0 \n",
      "  contourpy                           1.0.5-py311hdb19cb5_0 --> 1.3.1-py311hdb19cb5_0 \n",
      "  cookiecutter       pkgs/main/noarch::cookiecutter-1.7.3-~ --> pkgs/main/linux-64::cookiecutter-2.6.0-py311h06a4308_1 \n",
      "  cryptography                       41.0.3-py311hdda0065_0 --> 46.0.3-py311h0a354b3_0 \n",
      "  cssselect          pkgs/main/noarch::cssselect-1.1.0-pyh~ --> pkgs/main/linux-64::cssselect-1.2.0-py311h06a4308_0 \n",
      "  cyrus-sasl                              2.1.28-h52b45da_1 --> 2.1.28-h1110e0f_3 \n",
      "  cytoolz                            0.12.0-py311h5eee18b_0 --> 1.0.1-py311h5eee18b_0 \n",
      "  dal                               2023.1.1-hdb19cb5_48679 --> 2023.1.1-hdb19cb5_48680 \n",
      "  datashader                         0.15.2-py311h06a4308_0 --> 0.18.2-py311h06a4308_0 \n",
      "  dbus                                   1.13.18-hb2f20db_0 --> 1.16.2-h5bd4931_0 \n",
      "  debugpy                             1.6.7-py311h6a678d5_0 --> 1.8.16-py311hbdd6827_1 \n",
      "  decorator          pkgs/main/noarch::decorator-5.1.1-pyh~ --> pkgs/main/linux-64::decorator-5.2.1-py311h06a4308_0 \n",
      "  docstring-to-mark~                   0.11-py311h06a4308_0 --> 0.17-py311h06a4308_0 \n",
      "  docutils                           0.18.1-py311h06a4308_3 --> 0.21.2-py311h06a4308_1 \n",
      "  et_xmlfile                          1.1.0-py311h06a4308_0 --> 2.0.0-py311h06a4308_0 \n",
      "  executing          pkgs/main/noarch::executing-0.8.3-pyh~ --> pkgs/main/linux-64::executing-2.2.1-py311h06a4308_0 \n",
      "  expat                                    2.5.0-h6a678d5_0 --> 2.7.3-h3385a95_0 \n",
      "  filelock                            3.9.0-py311h06a4308_0 --> 3.20.0-py311h06a4308_0 \n",
      "  flask                               2.2.2-py311h06a4308_0 --> 3.1.2-py311h06a4308_0 \n",
      "  fmt                                      9.1.0-hdb19cb5_0 --> 9.1.0-hdb19cb5_1 \n",
      "  fontconfig                              2.14.1-h4c34cd2_2 --> 2.15.0-h2c49b7f_0 \n",
      "  fonttools          pkgs/main/noarch::fonttools-4.25.0-py~ --> pkgs/main/linux-64::fonttools-4.60.1-py311hee96239_0 \n",
      "  freetype                                2.12.1-h4a9f257_0 --> 2.13.3-h4a9f257_0 \n",
      "  frozenlist                          1.3.3-py311h5eee18b_0 --> 1.8.0-py311hbdd6827_0 \n",
      "  fsspec                           2023.4.0-py311h06a4308_0 --> 2025.10.0-py311h7040dfc_0 \n",
      "  future                             0.18.3-py311h06a4308_0 --> 1.0.0-py311h06a4308_0 \n",
      "  gensim                              4.3.0-py311hba01205_1 --> 4.4.0-py311hbdd6827_0 \n",
      "  gflags                                   2.2.2-he6710b0_0 --> 2.2.2-h6a678d5_1 \n",
      "  glib                                    2.69.1-he621ea3_2 --> 2.84.4-h5bdd934_0 \n",
      "  glog                                     0.5.0-h2531618_0 --> 0.5.0-h6a678d5_1 \n",
      "  gmp                                      6.2.1-h295c915_3 --> 6.3.0-h6a678d5_0 \n",
      "  gmpy2                               2.1.2-py311hc9b5ff0_0 --> 2.2.1-py311h5eee18b_0 \n",
      "  greenlet                            2.0.1-py311h6a678d5_0 --> 3.2.4-py311hbdd6827_0 \n",
      "  h5py                                3.9.0-py311hdd6beaf_0 --> 3.15.1-py311hea18c50_0 \n",
      "  hdf5                                    1.12.1-h2b7332f_3 --> 1.14.5-h2b7332f_2 \n",
      "  holoviews                          1.17.1-py311h06a4308_0 --> 1.22.0-py311h06a4308_0 \n",
      "  huggingface_hub                    0.15.1-py311h06a4308_0 --> 0.34.4-py311h06a4308_0 \n",
      "  hvplot                              0.8.4-py311h06a4308_0 --> 0.12.1-py311h06a4308_0 \n",
      "  icu                                       58.2-he6710b0_3 --> 73.1-h6a678d5_0 \n",
      "  idna                                  3.4-py311h06a4308_0 --> 3.11-py311h06a4308_0 \n",
      "  imageio                            2.31.1-py311h06a4308_0 --> 2.37.2-py311h7040dfc_0 \n",
      "  importlib-metadata                  6.0.0-py311h06a4308_0 --> 8.7.0-py311h06a4308_0 \n",
      "  incremental                           21.3.0-pyhd3eb1b0_0 --> 24.7.2-pyhd3eb1b0_0 \n",
      "  iniconfig          pkgs/main/noarch::iniconfig-1.1.1-pyh~ --> pkgs/main/linux-64::iniconfig-2.1.0-py311h06a4308_0 \n",
      "  intake                              0.6.8-py311h06a4308_0 --> 2.0.8-py311h06a4308_0 \n",
      "  intel-openmp                      2023.1.0-hdb19cb5_46305 --> 2023.1.0-hdb19cb5_46306 \n",
      "  ipykernel                          6.25.0-py311h92b7b1e_0 --> 6.31.0-py311h7040dfc_0 \n",
      "  ipython                            8.15.0-py311h06a4308_0 --> 8.30.0-py311h06a4308_0 \n",
      "  ipywidgets                          8.0.4-py311h06a4308_0 --> 8.1.7-py311h06a4308_0 \n",
      "  itemadapter        pkgs/main/noarch::itemadapter-0.3.0-p~ --> pkgs/main/linux-64::itemadapter-0.12.1-py311h06a4308_0 \n",
      "  itemloaders        pkgs/main/noarch::itemloaders-1.0.4-p~ --> pkgs/main/linux-64::itemloaders-1.3.2-py311h06a4308_0 \n",
      "  itsdangerous       pkgs/main/noarch::itsdangerous-2.0.1-~ --> pkgs/main/linux-64::itsdangerous-2.2.0-py311h06a4308_0 \n",
      "  jaraco.classes     pkgs/main/noarch::jaraco.classes-3.2.~ --> pkgs/main/linux-64::jaraco.classes-3.4.0-py311h06a4308_0 \n",
      "  jellyfish                           1.0.1-py311hb02cf49_0 --> 1.1.3-py311h4aa5aa6_0 \n",
      "  jinja2                              3.1.2-py311h06a4308_0 --> 3.1.6-py311h06a4308_0 \n",
      "  jmespath           pkgs/main/noarch::jmespath-0.10.0-pyh~ --> pkgs/main/linux-64::jmespath-1.0.1-py311h06a4308_0 \n",
      "  joblib                              1.2.0-py311h06a4308_0 --> 1.5.2-py311h06a4308_0 \n",
      "  jpeg                                        9e-h5eee18b_1 --> 9f-h5ce9db8_0 \n",
      "  jq                                      1.6-h27cfd23_1000 --> 1.8.1-h5eee18b_0 \n",
      "  json5              pkgs/main/noarch::json5-0.9.6-pyhd3eb~ --> pkgs/main/linux-64::json5-0.12.1-py311h06a4308_0 \n",
      "  jsonpatch          pkgs/main/noarch::jsonpatch-1.32-pyhd~ --> pkgs/main/linux-64::jsonpatch-1.33-py311h06a4308_1 \n",
      "  jsonpointer        pkgs/main/noarch::jsonpointer-2.1-pyh~ --> pkgs/main/linux-64::jsonpointer-3.0.0-py311h06a4308_0 \n",
      "  jsonschema                         4.17.3-py311h06a4308_0 --> 4.25.0-py311h06a4308_1 \n",
      "  jupyter                             1.0.0-py311h06a4308_8 --> 1.1.1-py311h06a4308_0 \n",
      "  jupyter_client                      7.4.9-py311h06a4308_0 --> 8.6.3-py311h06a4308_1 \n",
      "  jupyter_core                        5.3.0-py311h06a4308_0 --> 5.8.1-py311h06a4308_0 \n",
      "  jupyter_events                      0.6.3-py311h06a4308_0 --> 0.12.0-py311h06a4308_0 \n",
      "  jupyter_server                     1.23.4-py311h06a4308_0 --> 2.16.0-py311h06a4308_0 \n",
      "  jupyterlab                          3.6.3-py311h06a4308_0 --> 4.4.7-py311h06a4308_0 \n",
      "  jupyterlab_pygmen~ pkgs/main/noarch::jupyterlab_pygments~ --> pkgs/main/linux-64::jupyterlab_pygments-0.3.0-py311h06a4308_0 \n",
      "  jupyterlab_server                  2.22.0-py311h06a4308_0 --> 2.28.0-py311h06a4308_0 \n",
      "  jupyterlab_widgets                  3.0.5-py311h06a4308_0 --> 3.0.15-py311h06a4308_0 \n",
      "  keyring                           23.13.1-py311h06a4308_0 --> 25.7.0-py311h06a4308_0 \n",
      "  kiwisolver                          1.4.4-py311h6a678d5_0 --> 1.4.8-py311h6a678d5_0 \n",
      "  lazy-object-proxy                   1.6.0-py311h5eee18b_0 --> 1.12.0-py311hee96239_0 \n",
      "  lazy_loader                           0.2-py311h06a4308_0 --> 0.4-py311h06a4308_0 \n",
      "  lcms2                                     2.12-h3be6417_0 --> 2.16-h92b89f2_1 \n",
      "  ld_impl_linux-64                          2.38-h1181459_1 --> 2.44-h153f514_2 \n",
      "  lerc                                       3.0-h295c915_0 --> 4.0.0-h6a678d5_0 \n",
      "  libarchive                               3.6.2-h6ac8c49_2 --> 3.6.2-hfab0078_4 \n",
      "  libavif                                 0.11.1-h5eee18b_0 --> 1.3.0-h3539ee5_0 \n",
      "  libboost                               1.73.0-h28710b8_12 --> 1.82.0-h109eef0_2 \n",
      "  libbrotlicommon                          1.0.9-h5eee18b_7 --> 1.0.9-h5eee18b_9 \n",
      "  libbrotlidec                             1.0.9-h5eee18b_7 --> 1.0.9-h5eee18b_9 \n",
      "  libbrotlienc                             1.0.9-h5eee18b_7 --> 1.0.9-h5eee18b_9 \n",
      "  libcups                                  2.4.2-h2d74bed_1 --> 2.4.2-h252cb56_2 \n",
      "  libdeflate                                1.17-h5eee18b_0 --> 1.22-h5eee18b_0 \n",
      "  libedit                           3.1.20221030-h5eee18b_0 --> 3.1.20230828-h5eee18b_0 \n",
      "  libffi                                   3.4.4-h6a678d5_0 --> 3.4.4-h6a678d5_1 \n",
      "  libgcc-ng                               11.2.0-h1234567_1 --> 15.2.0-h166f726_7 \n",
      "  libgfortran-ng                          11.2.0-h00389a5_1 --> 15.2.0-h166f726_7 \n",
      "  libgfortran5                            11.2.0-h1234567_1 --> 15.2.0-hc633d37_7 \n",
      "  libgomp                                 11.2.0-h1234567_1 --> 15.2.0-h4751f2c_7 \n",
      "  liblief                                 0.12.3-h6a678d5_0 --> 0.16.4-h789ee31_1 \n",
      "  libllvm14                               14.0.6-hdb19cb5_3 --> 14.0.6-hecde1de_4 \n",
      "  libnghttp2                              1.52.0-h2d74bed_1 --> 1.67.1-h697f920_0 \n",
      "  libpng                                  1.6.39-h5eee18b_0 --> 1.6.50-h2ed474d_0 \n",
      "  libsodium                               1.0.18-h7b6447c_0 --> 1.0.20-heac8642_0 \n",
      "  libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-h6f1ccf3_2 \n",
      "  libssh2                                 1.10.0-hdbd6064_2 --> 1.11.1-h251f7ec_0 \n",
      "  libstdcxx-ng                            11.2.0-h1234567_1 --> 15.2.0-hc03a8fd_7 \n",
      "  libthrift                               0.15.0-h1795dd8_2 --> 0.15.0-hd8eb582_4 \n",
      "  libtiff                                  4.5.1-h6a678d5_0 --> 4.7.0-hde9077f_0 \n",
      "  libwebp-base                             1.3.2-h5eee18b_0 --> 1.6.0-hb7bb969_0 \n",
      "  libxcb                                    1.15-h7f8727e_0 --> 1.17.0-h9b100fa_0 \n",
      "  libxkbcommon                             1.0.1-h5eee18b_1 --> 1.9.1-h69220b7_0 \n",
      "  libxml2                                 2.10.4-hcbfbd50_0 --> 2.13.9-h2c43086_0 \n",
      "  libxslt                                 1.1.37-h2085143_0 --> 1.1.43-h28b3bda_0 \n",
      "  linkify-it-py                       2.0.0-py311h06a4308_0 --> 2.0.3-py311h06a4308_0 \n",
      "  lxml                                4.9.3-py311hdbbb534_0 --> 5.3.0-py311h57af460_1 \n",
      "  lz4                                 4.3.2-py311h5eee18b_0 --> 4.4.5-py311ha9de75d_0 \n",
      "  lz4-c                                    1.9.4-h6a678d5_0 --> 1.9.4-h6a678d5_1 \n",
      "  markdown                            3.4.1-py311h06a4308_0 --> 3.8-py311h06a4308_0 \n",
      "  markupsafe                          2.1.1-py311h5eee18b_0 --> 3.0.2-py311h5eee18b_0 \n",
      "  matplotlib                          3.7.2-py311h06a4308_0 --> 3.10.6-py311h06a4308_1 \n",
      "  matplotlib-base                     3.7.2-py311ha02d727_0 --> 3.10.6-py311h71dd3da_1 \n",
      "  matplotlib-inline                   0.1.6-py311h06a4308_0 --> 0.2.1-py311h06a4308_0 \n",
      "  mdit-py-plugins                     0.3.0-py311h06a4308_0 --> 0.5.0-py311h06a4308_0 \n",
      "  mdurl                               0.1.0-py311h06a4308_0 --> 0.1.2-py311h06a4308_0 \n",
      "  mistune                          0.8.4-py311h5eee18b_1000 --> 3.1.2-py311h06a4308_0 \n",
      "  mkl                               2023.1.0-h213fc3f_46343 --> 2023.1.0-h213fc3f_46344 \n",
      "  more-itertools     pkgs/main/noarch::more-itertools-8.12~ --> pkgs/main/linux-64::more-itertools-10.8.0-py311h06a4308_0 \n",
      "  mpc                                      1.1.0-h10f8cd9_1 --> 1.3.1-h5eee18b_0 \n",
      "  mpfr                                     4.0.2-hb69a4c5_1 --> 4.2.1-h5eee18b_0 \n",
      "  mpich                                    4.1.1-hbae89fd_0 --> 4.3.2-hf345156_0 \n",
      "  msgpack-python                      1.0.3-py311hdb19cb5_0 --> 1.1.1-py311h6a678d5_0 \n",
      "  multidict                           6.0.2-py311h5eee18b_0 --> 6.7.0-py311hee96239_0 \n",
      "  multipledispatch                    0.6.0-py311h06a4308_0 --> 1.0.0-py311h06a4308_0 \n",
      "  nbclient                           0.5.13-py311h06a4308_0 --> 0.10.2-py311h06a4308_0 \n",
      "  nbconvert                           6.5.4-py311h06a4308_0 --> 7.16.6-py311h06a4308_0 \n",
      "  nbformat                            5.9.2-py311h06a4308_0 --> 5.10.4-py311h06a4308_0 \n",
      "  ncurses                                    6.4-h6a678d5_0 --> 6.5-h7934f7d_0 \n",
      "  nest-asyncio                        1.5.6-py311h06a4308_0 --> 1.6.0-py311h06a4308_0 \n",
      "  networkx                              3.1-py311h06a4308_0 --> 3.4.2-py311h06a4308_0 \n",
      "  nltk                                3.8.1-py311h06a4308_0 --> 3.9.2-py311h19f43ea_0 \n",
      "  notebook                            6.5.4-py311h06a4308_1 --> 7.4.5-py311h06a4308_0 \n",
      "  notebook-shim                       0.2.2-py311h06a4308_0 --> 0.2.4-py311h06a4308_0 \n",
      "  nspr                                      4.35-h6a678d5_0 --> 4.37-h8459abe_0 \n",
      "  numpydoc                            1.5.0-py311h06a4308_0 --> 1.9.0-py311h06a4308_0 \n",
      "  oniguruma                              6.9.7.1-h27cfd23_0 --> 6.9.10-hb25bd0a_0 \n",
      "  openpyxl                           3.0.10-py311h5eee18b_0 --> 3.1.5-py311h5eee18b_1 \n",
      "  openssl                                 3.0.10-h7f8727e_2 --> 3.0.18-hd6dcaed_0 \n",
      "  packaging                            23.1-py311h06a4308_0 --> 25.0-py311h06a4308_1 \n",
      "  pandas                              2.0.3-py311ha02d727_0 --> 2.3.3-py311h23c847b_1 \n",
      "  pandocfilters      pkgs/main/noarch::pandocfilters-1.5.0~ --> pkgs/main/linux-64::pandocfilters-1.5.1-py311h06a4308_0 \n",
      "  panel                               1.2.3-py311h06a4308_0 --> 1.8.3-py311h06a4308_0 \n",
      "  param                              1.13.0-py311h06a4308_0 --> 2.3.0-py311h06a4308_0 \n",
      "  parsel                              1.6.0-py311h06a4308_0 --> 1.10.0-py311h06a4308_0 \n",
      "  parso              pkgs/main/noarch::parso-0.8.3-pyhd3eb~ --> pkgs/main/linux-64::parso-0.8.5-py311h06a4308_0 \n",
      "  partd                               1.4.0-py311h06a4308_0 --> 1.4.2-py311h06a4308_0 \n",
      "  patch                                 2.7.6-h7b6447c_1001 --> 2.8-hb25bd0a_0 \n",
      "  pathspec                           0.10.3-py311h06a4308_0 --> 0.12.1-py311h06a4308_1 \n",
      "  patsy                               0.5.3-py311h06a4308_0 --> 1.0.1-py311h06a4308_0 \n",
      "  pcre2                                    10.42-hebb0a14_0 --> 10.46-hf426167_0 \n",
      "  pexpect            pkgs/main/noarch::pexpect-4.8.0-pyhd3~ --> pkgs/main/linux-64::pexpect-4.9.0-py311h06a4308_1 \n",
      "  pillow                              9.4.0-py311h6a678d5_1 --> 12.0.0-py311h3b88751_1 \n",
      "  pkginfo                             1.9.6-py311h06a4308_0 --> 1.12.0-py311h06a4308_0 \n",
      "  platformdirs                       3.10.0-py311h06a4308_0 --> 4.5.0-py311h06a4308_0 \n",
      "  plotly                              5.9.0-py311h06a4308_0 --> 6.3.0-py311he3bba80_0 \n",
      "  pluggy                              1.0.0-py311h06a4308_1 --> 1.5.0-py311h06a4308_0 \n",
      "  prometheus_client                  0.14.1-py311h06a4308_0 --> 0.21.1-py311h06a4308_0 \n",
      "  prompt-toolkit                     3.0.36-py311h06a4308_0 --> 3.0.52-py311h06a4308_1 \n",
      "  prompt_toolkit                          3.0.36-hd3eb1b0_0 --> 3.0.52-hd3eb1b0_1 \n",
      "  protego             pkgs/main/noarch::protego-0.1.16-py_0 --> pkgs/main/linux-64::protego-0.4.0-py311h06a4308_0 \n",
      "  psutil                              5.9.0-py311h5eee18b_0 --> 7.0.0-py311hee96239_1 \n",
      "  ptyprocess                             0.7.0-pyhd3eb1b0_2 --> 0.7.0-pyhd3eb1b0_3 \n",
      "  pure_eval          pkgs/main/noarch::pure_eval-0.2.2-pyh~ --> pkgs/main/linux-64::pure_eval-0.2.3-py311h06a4308_0 \n",
      "  py-cpuinfo         pkgs/main/noarch::py-cpuinfo-8.0.0-py~ --> pkgs/main/linux-64::py-cpuinfo-9.0.0-py311h06a4308_0 \n",
      "  py-lief                            0.12.3-py311h6a678d5_0 --> 0.16.4-py311h789ee31_1 \n",
      "  pyasn1             pkgs/main/noarch::pyasn1-0.4.8-pyhd3e~ --> pkgs/main/linux-64::pyasn1-0.6.1-py311h06a4308_0 \n",
      "  pyasn1-modules     pkgs/main/noarch::pyasn1-modules-0.2.~ --> pkgs/main/linux-64::pyasn1-modules-0.4.2-py311h06a4308_0 \n",
      "  pycosat                             0.6.4-py311h5eee18b_0 --> 0.6.6-py311h5eee18b_2 \n",
      "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd~ --> pkgs/main/linux-64::pycparser-2.23-py311h06a4308_0 \n",
      "  pyct                                0.5.0-py311h06a4308_0 --> 0.6.0-py311h06a4308_0 \n",
      "  pydantic                           1.10.8-py311h5eee18b_0 --> 1.10.19-py311h5eee18b_0 \n",
      "  pydispatcher                        2.0.5-py311h06a4308_2 --> 2.0.7-py311h06a4308_0 \n",
      "  pyerfa                              2.0.0-py311h5eee18b_0 --> 2.0.1.5-py311h5eee18b_0 \n",
      "  pygments                           2.15.1-py311h06a4308_1 --> 2.19.2-py311h06a4308_0 \n",
      "  pyjwt                               2.4.0-py311h06a4308_0 --> 2.10.1-py311h06a4308_0 \n",
      "  pylint-venv                         2.3.0-py311h06a4308_0 --> 3.0.3-py311h06a4308_0 \n",
      "  pyodbc                             4.0.34-py311h6a678d5_0 --> 5.3.0-py311hab19121_0 \n",
      "  pyopenssl                          23.2.0-py311h06a4308_0 --> 25.3.0-py311hef88997_0 \n",
      "  pyparsing                           3.0.9-py311h06a4308_0 --> 3.2.5-py311h06a4308_0 \n",
      "  pyqt                               5.15.7-py311h6a678d5_0 --> 5.15.10-py311h6a678d5_1 \n",
      "  pyqt5-sip                         12.11.0-py311h6a678d5_0 --> 12.13.0-py311h5eee18b_1 \n",
      "  pyqtwebengine                      5.15.7-py311h6a678d5_0 --> 5.15.10-py311h6a678d5_1 \n",
      "  pysocks                             1.7.1-py311h06a4308_0 --> 1.7.1-py311h06a4308_1 \n",
      "  pytables                            3.8.0-py311hb8ae3fc_3 --> 3.10.2-py311h759fa19_1 \n",
      "  pytest                              7.4.0-py311h06a4308_0 --> 8.4.2-py311h06a4308_0 \n",
      "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8~ --> pkgs/main/linux-64::python-dateutil-2.9.0post0-py311h06a4308_2 \n",
      "  python-dotenv                      0.21.0-py311h06a4308_0 --> 1.1.0-py311h06a4308_0 \n",
      "  python-fastjsonsc~                 2.16.2-py311h06a4308_0 --> 2.21.2-py311h06a4308_0 \n",
      "  python-json-logger                  2.0.7-py311h06a4308_0 --> 3.2.1-py311h06a4308_0 \n",
      "  python-libarchive~                       2.9-pyhd3eb1b0_1 --> 5.1-pyhd3eb1b0_0 \n",
      "  python-lmdb                         1.4.1-py311h6a678d5_0 --> 1.6.2-py311h6a678d5_0 \n",
      "  python-lsp-black                    1.2.1-py311h06a4308_0 --> 2.0.0-py311h06a4308_1 \n",
      "  python-lsp-jsonrpc                     1.0.0-pyhd3eb1b0_0 --> 1.1.2-pyhd3eb1b0_0 \n",
      "  python-slugify     pkgs/main/noarch::python-slugify-5.0.~ --> pkgs/main/linux-64::python-slugify-8.0.4-py311h06a4308_0 \n",
      "  python-tzdata                         2023.3-pyhd3eb1b0_0 --> 2025.2-pyhd3eb1b0_0 \n",
      "  python-xxhash                       2.0.2-py311h5eee18b_1 --> 3.5.0-py311h5eee18b_0 \n",
      "  pytoolconfig                        1.2.5-py311h06a4308_1 --> 1.2.6-py311h06a4308_0 \n",
      "  pytz                         2023.3.post1-py311h06a4308_0 --> 2025.2-py311h06a4308_0 \n",
      "  pyviz_comms                         2.3.0-py311h06a4308_0 --> 3.0.6-py311h06a4308_0 \n",
      "  pywavelets                          1.4.1-py311h5eee18b_0 --> 1.8.0-py311h5eee18b_0 \n",
      "  pyxdg              pkgs/main/noarch::pyxdg-0.27-pyhd3eb1~ --> pkgs/main/linux-64::pyxdg-0.28-py311h06a4308_0 \n",
      "  pyyaml                                6.0-py311h5eee18b_1 --> 6.0.3-py311h591646f_0 \n",
      "  pyzmq                              23.2.0-py311h6a678d5_0 --> 27.1.0-py311hcf8288c_1 \n",
      "  qt-main                                 5.15.2-h7358343_9 --> 5.15.2-h53bd1ea_10 \n",
      "  qt-webengine                            5.15.9-h9ab4d14_7 --> 5.15.9-he2071f7_8 \n",
      "  qtawesome                           1.2.2-py311h06a4308_0 --> 1.4.0-py311h06a4308_0 \n",
      "  qtpy                                2.2.0-py311h06a4308_0 --> 2.4.3-py311h06a4308_0 \n",
      "  queuelib                            1.5.0-py311h06a4308_0 --> 1.8.0-py311h06a4308_0 \n",
      "  readline                                   8.2-h5eee18b_0 --> 8.3-hc2a1206_0 \n",
      "  regex                            2022.7.9-py311h5eee18b_0 --> 2025.9.1-py311hee96239_0 \n",
      "  reproc                                  14.2.4-h295c915_1 --> 14.2.4-h6a678d5_2 \n",
      "  reproc-cpp                              14.2.4-h295c915_1 --> 14.2.4-h6a678d5_2 \n",
      "  requests                           2.31.0-py311h06a4308_0 --> 2.32.5-py311h06a4308_1 \n",
      "  requests-file      pkgs/main/noarch::requests-file-1.5.1~ --> pkgs/main/linux-64::requests-file-2.1.0-py311h06a4308_0 \n",
      "  rope                                1.7.0-py311h06a4308_0 --> 1.14.0-py311h06a4308_0 \n",
      "  rtree                               1.0.1-py311h06a4308_0 --> 1.4.1-py311hd60ff07_0 \n",
      "  s3fs                             2023.4.0-py311h06a4308_0 --> 2025.10.0-py311h06a4308_0 \n",
      "  safetensors                         0.3.2-py311hb02cf49_0 --> 0.6.2-py311h498d7c9_0 \n",
      "  scikit-image                       0.20.0-py311h6a678d5_0 --> 0.25.2-py311hc74f9fe_0 \n",
      "  scikit-learn                        1.3.0-py311ha02d727_0 --> 1.7.2-py311h505adc9_0 \n",
      "  scipy                              1.11.1-py311h08b1b3b_0 --> 1.15.3-py311h525edd1_0 \n",
      "  scrapy                              2.8.0-py311h06a4308_0 --> 2.13.3-py311h06a4308_0 \n",
      "  seaborn                            0.12.2-py311h06a4308_0 --> 0.13.2-py311h06a4308_3 \n",
      "  secretstorage                       3.3.1-py311h06a4308_1 --> 3.4.0-py311h3e8c6aa_0 \n",
      "  send2trash         pkgs/main/noarch::send2trash-1.8.0-py~ --> pkgs/main/linux-64::send2trash-1.8.2-py311h06a4308_1 \n",
      "  service_identity   pkgs/main/noarch::service_identity-18~ --> pkgs/main/linux-64::service_identity-24.2.0-py311h06a4308_0 \n",
      "  sip                                 6.6.2-py311h6a678d5_0 --> 6.7.12-py311h6a678d5_1 \n",
      "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1~ --> pkgs/main/linux-64::six-1.17.0-py311h06a4308_0 \n",
      "  smart_open                          5.2.1-py311h06a4308_0 --> 7.3.1-py311h06a4308_0 \n",
      "  snappy                                   1.1.9-h295c915_0 --> 1.2.1-h6a678d5_0 \n",
      "  sniffio                             1.2.0-py311h06a4308_1 --> 1.3.0-py311h06a4308_0 \n",
      "  snowballstemmer    pkgs/main/noarch::snowballstemmer-2.2~ --> pkgs/main/linux-64::snowballstemmer-3.0.1-py311h06a4308_0 \n",
      "  soupsieve                             2.4-py311h06a4308_0 --> 2.5-py311h06a4308_0 \n",
      "  sphinx                              5.0.2-py311h06a4308_0 --> 8.2.3-py311h5eee18b_0 \n",
      "  sphinxcontrib-app~                     1.0.2-pyhd3eb1b0_0 --> 2.0.0-pyhd3eb1b0_1 \n",
      "  sphinxcontrib-dev~                     1.0.2-pyhd3eb1b0_0 --> 2.0.0-pyhd3eb1b0_0 \n",
      "  sphinxcontrib-htm~                     2.0.0-pyhd3eb1b0_0 --> 2.1.0-pyhd3eb1b0_0 \n",
      "  sphinxcontrib-qth~                     1.0.3-pyhd3eb1b0_0 --> 2.0.0-pyhd3eb1b0_1 \n",
      "  sphinxcontrib-ser~                     1.1.5-pyhd3eb1b0_0 --> 2.0.0-pyhd3eb1b0_0 \n",
      "  sqlalchemy                         1.4.39-py311h5eee18b_0 --> 2.0.43-py311h7e39e78_0 \n",
      "  sqlite                                  3.41.2-h5eee18b_0 --> 3.51.0-h2a70700_0 \n",
      "  stack_data         pkgs/main/noarch::stack_data-0.2.0-py~ --> pkgs/main/linux-64::stack_data-0.6.3-py311h06a4308_0 \n",
      "  statsmodels                        0.14.0-py311hf4808d0_0 --> 0.14.5-py311h76ea63d_0 \n",
      "  sympy                              1.11.1-py311h06a4308_0 --> 1.14.0-py311h06a4308_0 \n",
      "  tabulate                           0.8.10-py311h06a4308_0 --> 0.9.0-py311h06a4308_0 \n",
      "  tblib              pkgs/main/noarch::tblib-1.7.0-pyhd3eb~ --> pkgs/main/linux-64::tblib-3.1.0-py311h06a4308_0 \n",
      "  terminado                          0.17.1-py311h06a4308_0 --> 0.18.1-py311h06a4308_0 \n",
      "  textdistance       pkgs/main/noarch::textdistance-4.2.1-~ --> pkgs/main/linux-64::textdistance-4.6.3-py311he3bba80_1 \n",
      "  threadpoolctl      pkgs/main/noarch::threadpoolctl-2.2.0~ --> pkgs/main/linux-64::threadpoolctl-3.5.0-py311h92b7b1e_0 \n",
      "  tifffile                        2023.4.12-py311h06a4308_0 --> 2025.10.4-py311h06a4308_0 \n",
      "  tinycss2                            1.2.1-py311h06a4308_0 --> 1.4.0-py311h06a4308_0 \n",
      "  tk                                      8.6.12-h1ccaba5_0 --> 8.6.15-h54e0aa7_0 \n",
      "  tldextract         pkgs/main/noarch::tldextract-3.2.0-py~ --> pkgs/main/linux-64::tldextract-5.1.2-py311h06a4308_0 \n",
      "  tomlkit                            0.11.1-py311h06a4308_0 --> 0.13.3-py311h06a4308_0 \n",
      "  toolz                              0.12.0-py311h06a4308_0 --> 1.0.0-py311h06a4308_0 \n",
      "  tornado                             6.3.2-py311h5eee18b_0 --> 6.5.1-py311h5eee18b_0 \n",
      "  tqdm                               4.65.0-py311h92b7b1e_0 --> 4.67.1-py311h7040dfc_1 \n",
      "  traitlets                           5.7.1-py311h06a4308_0 --> 5.14.3-py311h06a4308_0 \n",
      "  twisted                           22.10.0-py311h5eee18b_0 --> 25.5.0-py311h06a4308_0 \n",
      "  typing-extensions                   4.7.1-py311h06a4308_0 --> 4.15.0-py311h06a4308_0 \n",
      "  typing_extensions                   4.7.1-py311h06a4308_0 --> 4.15.0-py311h06a4308_0 \n",
      "  tzdata                                   2023c-h04d1e81_0 --> 2025b-h04d1e81_0 \n",
      "  uc-micro-py                         1.0.1-py311h06a4308_0 --> 1.0.3-py311h06a4308_0 \n",
      "  ujson                               5.4.0-py311h6a678d5_0 --> 5.11.0-py311hbdd6827_0 \n",
      "  unixodbc                                2.3.11-h5eee18b_0 --> 2.3.14-h10e04f9_0 \n",
      "  urllib3                           1.26.16-py311h06a4308_0 --> 2.5.0-py311h06a4308_0 \n",
      "  utf8proc                                 2.6.1-h27cfd23_0 --> 2.6.1-h5eee18b_1 \n",
      "  w3lib              pkgs/main/noarch::w3lib-1.21.0-pyhd3e~ --> pkgs/main/linux-64::w3lib-2.1.2-py311h06a4308_0 \n",
      "  watchdog                            2.1.6-py311h06a4308_0 --> 6.0.0-py311h06a4308_0 \n",
      "  wcwidth            pkgs/main/noarch::wcwidth-0.2.5-pyhd3~ --> pkgs/main/linux-64::wcwidth-0.2.13-py311h06a4308_0 \n",
      "  websocket-client                   0.58.0-py311h06a4308_4 --> 1.8.0-py311h06a4308_0 \n",
      "  werkzeug                            2.2.3-py311h06a4308_0 --> 3.1.3-py311h06a4308_0 \n",
      "  whatthepatch                        1.0.2-py311h06a4308_0 --> 1.0.7-py311h06a4308_0 \n",
      "  widgetsnbextension                  4.0.5-py311h06a4308_0 --> 4.0.14-py311h06a4308_0 \n",
      "  wrapt                              1.14.1-py311h5eee18b_0 --> 1.17.0-py311h5eee18b_0 \n",
      "  wurlitzer                           3.0.2-py311h06a4308_0 --> 3.1.1-py311h06a4308_0 \n",
      "  xarray                           2023.6.0-py311h06a4308_0 --> 2025.4.0-py311h06a4308_0 \n",
      "  xyzservices                      2022.9.0-py311h06a4308_1 --> 2025.4.0-py311h06a4308_0 \n",
      "  xz                                       5.4.2-h5eee18b_0 --> 5.6.4-h5eee18b_1 \n",
      "  yarl                                1.8.1-py311h5eee18b_0 --> 1.22.0-py311hee96239_0 \n",
      "  zeromq                                   4.3.4-h2531618_0 --> 4.3.5-hb0a5e54_1 \n",
      "  zict                                2.2.0-py311h06a4308_0 --> 3.0.0-py311h06a4308_0 \n",
      "  zipp                               3.11.0-py311h06a4308_0 --> 3.23.0-py311h06a4308_0 \n",
      "  zlib                                    1.2.13-h5eee18b_0 --> 1.2.13-hd233ad5_2 \n",
      "  zope.interface                      5.4.0-py311h5eee18b_0 --> 8.0.1-py311hee96239_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n",
      "  environment location: /sw/eb/sw/Anaconda3/2023.09-0\n",
      "  uid: 54240\n",
      "  gid: 54240\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!conda update -n base -c defaults conda -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "125cd57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 25.9.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.9.1\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /sw/eb/sw/Anaconda3/2023.09-0\n",
      "\n",
      "  added / updated specs:\n",
      "    - transformers\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2023.08.22-h06a4308_0 --> 2025.11.4-h06a4308_0 \n",
      "  certifi                         2023.7.22-py311h06a4308_0 --> 2025.11.12-py311h06a4308_0 \n",
      "  openssl                                 3.0.10-h7f8727e_2 --> 3.0.18-hd6dcaed_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n",
      "  environment location: /sw/eb/sw/Anaconda3/2023.09-0\n",
      "  uid: 54240\n",
      "  gid: 54240\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c huggingface transformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16a888e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import libraries needed for transformer model \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpreprocess\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodel\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrain_eval\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'preprocess'"
     ]
    }
   ],
   "source": [
    "# import libraries needed for transformer model \n",
    "import transformers\n",
    "import preprocess\n",
    "import model\n",
    "import train_eval\n",
    "\n",
    "print(\"All imports succeeded ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c875654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Make sure we're in the repo root \n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Contents:\", os.listdir(\".\"))\n",
    "\n",
    "# So that `src.*` imports work\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "from src.preprocess import load_and_preprocess\n",
    "from src.model import create_model\n",
    "from src.train_eval import train_model\n",
    "from src.utils import plot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4d98c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file from: /ccstar/scratch/user/u.jg335414/ml_final/ML_DisasterResponse-main/data/tweets.csv\n",
      "Dataset shape: (11370, 5)\n",
      "   id keyword        location  \\\n",
      "0   0  ablaze             NaN   \n",
      "1   1  ablaze             NaN   \n",
      "2   2  ablaze   New York City   \n",
      "3   3  ablaze  Morgantown, WV   \n",
      "4   4  ablaze             NaN   \n",
      "\n",
      "                                                text  target  \n",
      "0  Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
      "1  Telangana: Section 144 has been imposed in Bha...       1  \n",
      "2  Arsonist sets cars ablaze at dealership https:...       1  \n",
      "3  Arsonist sets cars ablaze at dealership https:...       1  \n",
      "4  \"Lord Jesus, your love brings freedom and pard...       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 569/569 [00:46<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.2796, Val Acc: 0.8993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 569/569 [00:47<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 0.1498, Val Acc: 0.9103\n",
      "Training complete. Metrics and plots saved.\n"
     ]
    }
   ],
   "source": [
    "# Run transformer model \n",
    "# 1. Load and preprocess the data\n",
    "train_enc, val_enc, train_labels, val_labels, num_labels = load_and_preprocess(\"data/tweets.csv\")\n",
    "\n",
    "# 2. Create the BERT model\n",
    "model = create_model(num_labels)\n",
    "\n",
    "# (Optional) explicitly move to GPU, if train_model doesn't already do it inside\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 3. Train the model\n",
    "train_losses, val_accs = train_model(\n",
    "    model,\n",
    "    train_enc,\n",
    "    val_enc,\n",
    "    train_labels,\n",
    "    val_labels,\n",
    ")\n",
    "\n",
    "# 4. Plot metrics (this likely saves a PNG and/or shows a plot)\n",
    "plot_metrics(train_losses, val_accs)\n",
    "\n",
    "print(\"Training complete. Metrics and plots saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a06f49cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(model, train_enc, val_enc, train_labels, val_labels, epochs=2, batch_size=16, lr=2e-05)\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import src.train_eval as train_eval\n",
    "\n",
    "print(inspect.signature(train_eval.train_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb16e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 569/569 [00:46<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.0675, Val Acc: 0.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 569/569 [00:46<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 0.0353, Val Acc: 0.8936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 569/569 [00:46<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss: 0.0229, Val Acc: 0.9028\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_accs = train_model(\n",
    "    model,\n",
    "    train_enc,\n",
    "    val_enc,\n",
    "    train_labels,\n",
    "    val_labels,\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f493b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess: ['BertTokenizer', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'load_and_preprocess', 'os', 'pd', 'plt', 'train_test_split']\n",
      "model: ['BertForSequenceClassification', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'create_model', 'nn', 'torch']\n",
      "train_eval: ['DataLoader', 'TensorDataset', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'plt', 'torch', 'tqdm', 'train_model']\n"
     ]
    }
   ],
   "source": [
    "import preprocess\n",
    "import model\n",
    "import train_eval\n",
    "\n",
    "print(\"preprocess:\", dir(preprocess)[:20])\n",
    "print(\"model:\", dir(model)[:20])\n",
    "print(\"train_eval:\", dir(train_eval)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c417408f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def train_model(model, train_enc, val_enc, train_labels, val_labels, epochs=2, batch_size=16, lr=2e-5):\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "    model.to(device)\n",
      "\n",
      "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
      "    loss_fn = torch.nn.CrossEntropyLoss()\n",
      "\n",
      "    # Prepare data loaders\n",
      "    train_data = TensorDataset(train_enc[\"input_ids\"], train_enc[\"attention_mask\"], torch.tensor(train_labels))\n",
      "    val_data = TensorDataset(val_enc[\"input_ids\"], val_enc[\"attention_mask\"], torch.tensor(val_labels))\n",
      "\n",
      "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
      "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
      "\n",
      "    train_losses, val_accs = [], []\n",
      "\n",
      "    for epoch in range(epochs):\n",
      "        model.train()\n",
      "        total_loss = 0\n",
      "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
      "            b_input_ids, b_attn_mask, b_labels = [t.to(device) for t in batch]\n",
      "\n",
      "            optimizer.zero_grad()\n",
      "            outputs = model(input_ids=b_input_ids, attention_mask=b_attn_mask, labels=b_labels)\n",
      "            loss = outputs.loss\n",
      "            total_loss += loss.item()\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "\n",
      "        avg_train_loss = total_loss / len(train_loader)\n",
      "        train_losses.append(avg_train_loss)\n",
      "\n",
      "        # Validation\n",
      "        model.eval()\n",
      "        correct, total = 0, 0\n",
      "        with torch.no_grad():\n",
      "            for batch in val_loader:\n",
      "                b_input_ids, b_attn_mask, b_labels = [t.to(device) for t in batch]\n",
      "                outputs = model(input_ids=b_input_ids, attention_mask=b_attn_mask)\n",
      "                preds = torch.argmax(outputs.logits, dim=1)\n",
      "                correct += (preds == b_labels).sum().item()\n",
      "                total += b_labels.size(0)\n",
      "\n",
      "        val_acc = correct / total\n",
      "        val_accs.append(val_acc)\n",
      "\n",
      "        print(f\"Epoch {epoch+1} - Loss: {avg_train_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
      "\n",
      "    # Plot loss curve\n",
      "    plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
      "    plt.title(\"Training Loss Curve\")\n",
      "    plt.xlabel(\"Epoch\")\n",
      "    plt.ylabel(\"Loss\")\n",
      "    plt.legend()\n",
      "    plt.savefig(\"training_loss_curve.png\")\n",
      "    plt.close()\n",
      "\n",
      "    return train_losses, val_accs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import src.train_eval as tv\n",
    "\n",
    "print(inspect.getsource(tv.train_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a8a5f3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpreprocess\u001b[39;00m\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m preprocess\u001b[38;5;241m.\u001b[39mload_and_preprocess(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweets.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of returned objects:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(result))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'preprocess'"
     ]
    }
   ],
   "source": [
    "import preprocess\n",
    "\n",
    "result = preprocess.load_and_preprocess(\"tweets.csv\")\n",
    "print(\"Number of returned objects:\", len(result))\n",
    "for i, item in enumerate(result):\n",
    "    print(i, type(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3ab544",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m  \u001b[38;5;66;03m# from your earlier code\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer  # from your earlier code\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fac3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
